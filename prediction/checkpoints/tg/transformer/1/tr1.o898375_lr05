Start training...
Finished training of 0th model of 1 repeat times! Best validation results from epoch 75.
Model saved as ./checkpoints/tg/transformer/1/0.pt.
train		mae: 29.7028    	rmse: 43.1980    	lgmae: 0.3981     	r2: 0.8544     	
valid		mae: 33.5593    	rmse: 48.5542    	lgmae: 0.4181     	r2: 0.8034     	
Start training...
Finished training of 1th model of 1 repeat times! Best validation results from epoch 108.
Model saved as ./checkpoints/tg/transformer/1/1.pt.
train		mae: 25.9489    	rmse: 38.4221    	lgmae: 0.3667     	r2: 0.8848     	
valid		mae: 32.2412    	rmse: 46.1912    	lgmae: 0.4069     	r2: 0.8221     	
Start training...
Finished training of 2th model of 1 repeat times! Best validation results from epoch 140.
Model saved as ./checkpoints/tg/transformer/1/2.pt.
train		mae: 22.9754    	rmse: 34.8558    	lgmae: 0.3410     	r2: 0.9052     	
valid		mae: 30.8210    	rmse: 45.2281    	lgmae: 0.3859     	r2: 0.8294     	
Start training...
Finished training of 3th model of 1 repeat times! Best validation results from epoch 121.
Model saved as ./checkpoints/tg/transformer/1/3.pt.
train		mae: 26.8287    	rmse: 39.5021    	lgmae: 0.3728     	r2: 0.8782     	
valid		mae: 32.1818    	rmse: 45.7473    	lgmae: 0.3787     	r2: 0.8255     	
Finished training for all 4 models of 1 repeat times!
Start training...
Finished training of 0th model of 2 repeat times! Best validation results from epoch 109.
Model saved as ./checkpoints/tg/transformer/2/0.pt.
train		mae: 25.7825    	rmse: 38.2225    	lgmae: 0.3506     	r2: 0.8860     	
valid		mae: 32.1681    	rmse: 46.7764    	lgmae: 0.4075     	r2: 0.8176     	
Start training...
Finished training of 1th model of 2 repeat times! Best validation results from epoch 118.
Model saved as ./checkpoints/tg/transformer/2/1.pt.
train		mae: 25.3405    	rmse: 37.1210    	lgmae: 0.3474     	r2: 0.8925     	
valid		mae: 31.6798    	rmse: 45.5245    	lgmae: 0.3990     	r2: 0.8272     	
Start training...
Finished training of 2th model of 2 repeat times! Best validation results from epoch 105.
Model saved as ./checkpoints/tg/transformer/2/2.pt.
train		mae: 25.2416    	rmse: 37.3277    	lgmae: 0.3497     	r2: 0.8913     	
valid		mae: 32.0807    	rmse: 46.8220    	lgmae: 0.4113     	r2: 0.8172     	
Start training...
Finished training of 3th model of 2 repeat times! Best validation results from epoch 149.
Model saved as ./checkpoints/tg/transformer/2/3.pt.
train		mae: 22.2326    	rmse: 33.8682    	lgmae: 0.3065     	r2: 0.9105     	
valid		mae: 30.4771    	rmse: 45.6940    	lgmae: 0.3738     	r2: 0.8259     	
Start training...
Finished training of 4th model of 2 repeat times! Best validation results from epoch 198.
Model saved as ./checkpoints/tg/transformer/2/4.pt.
train		mae: 19.1836    	rmse: 29.9865    	lgmae: 0.2885     	r2: 0.9298     	
valid		mae: 30.0892    	rmse: 45.2789    	lgmae: 0.3870     	r2: 0.8291     	
Finished training for all 5 models of 2 repeat times!
Start training...
Traceback (most recent call last):
  File "/scratch365/yzhu25/challenge-code/prediction/run.py", line 34, in <module>
    t.main()
  File "/scratch365/yzhu25/challenge-code/prediction/tsfm_main.py", line 270, in main
    model,device,best_train,best_valid = self.model_seed(i, train_loader, valid_loader)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch365/yzhu25/challenge-code/prediction/tsfm_main.py", line 199, in model_seed
    self.training(model, train_loader, optimizer, device)
  File "/scratch365/yzhu25/challenge-code/prediction/tsfm_main.py", line 89, in training
    loss.backward()
  File "/afs/crc.nd.edu/user/y/yzhu25/.conda/envs/py311/lib/python3.11/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/afs/crc.nd.edu/user/y/yzhu25/.conda/envs/py311/lib/python3.11/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacty of 47.53 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 45.34 GiB memory in use. Of the allocated memory 43.50 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
